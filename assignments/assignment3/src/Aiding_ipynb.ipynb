{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Word-embeddings. The aiding notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to load in the data: \n",
    "We'll do that as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath = os.path.join(\"..\", \"data\", \"spot_mil_song_lyr.csv\")\n",
    "lyrics = pd.read_csv(inpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to load a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I want to tak a given word as an input and find the most similar words via word embeddings: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "love_words = model.most_similar(positive=\"love\", topn=10)\n",
    "lov_wor = [i[0] for i in love_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will here take the opportunity for a little interpretive freedom and pick the 10 words, that I find also has a peculiar 'love-athmosphere'. I therefore exclude me and my from the dataset, because they can also appear in many other songs. I find that this would be valuable to somehow integrate in the script, since the words 'me' and 'my' (from the raw preprocessing) disturb the calculations heavily!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lov_wor = [\"dream\", \"life\", \"dreams\", \"loves\", \"loving\", \"wonder\", \"soul\", \"loved\", \"crazy\", \"happy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I need to find the number, these word appear in a given text per author:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "artist_list = []\n",
    "\n",
    "for index, row in lyrics.iterrows():\n",
    "    lyr = row['text']\n",
    "    lyr = re.sub(r'[^\\w\\s]', ' ', lyr)\n",
    "\n",
    "    if any(ele in lyr for ele in lov_wor): #Moving into the rows with the words https://www.geeksforgeeks.org/python-test-if-string-contains-element-from-list/\n",
    "        artist_list.append(row['artist'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have the calculation based on artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The artist ABBA sing about love 113 out of 113 times.\n"
     ]
    }
   ],
   "source": [
    "artist_entry = \"ABBA\"\n",
    "lov_songs = artist_list.count(artist_entry)\n",
    "tot_songs = lyrics['artist'].value_counts()[artist_entry]\n",
    "\n",
    "print(\"The artist \" + artist + \" sing about love \" + str(lov_songs) + \" out of \" + str(tot_songs) + \" times.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra function, that tells me how much the given song is a love song (how many words are represented in the love corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_lov_song():\n",
    "    tot_wor_count = len(list(lyr.split(\" \"))) \n",
    "    lov_wor_count = 0\n",
    "    for word in lov_wor:\n",
    "        wor_count = len(re.findall(word, lyr))\n",
    "        lov_wor_count = lov_wor_count + wor_count\n",
    "\n",
    "    perc_lov_wor = round(lov_wor_count/tot_wor_count*100,2)\n",
    "\n",
    "    print(\"The song \" + row['song'] + \" is \" + str(perc_lov_wor) + \" percent love-song\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env240315",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
